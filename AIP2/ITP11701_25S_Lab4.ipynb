{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfCqmnabCU6K"
   },
   "source": [
    "# ITP11701\n",
    "# Lab Session 04 : Logistic Regression & Softmax Classification\n",
    "\n",
    "#### File name must be **aip2_lab4_student_id.ipynb**, example: **aip2_lab4_20250000.ipynb**\n",
    "#### Fill in the blanks in the following cells and submit the notebook file\n",
    "\n",
    "**YongHun Lee**, 2025-05-07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEnpTG8HCU6Q"
   },
   "source": [
    "# 1. Data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1649364781662,
     "user": {
      "displayName": "이민지",
      "userId": "04887021204234205393"
     },
     "user_tz": -540
    },
    "id": "fPH4SFpPDPN0",
    "outputId": "c99e60a6-cf86-4c59-d572-36ae4f491b59"
   },
   "outputs": [],
   "source": [
    "#Import the datasets from sklearn module\n",
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()\n",
    "\n",
    "#The iris data contain following information-\n",
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1649309783075,
     "user": {
      "displayName": "이민지",
      "userId": "04887021204234205393"
     },
     "user_tz": -540
    },
    "id": "Dfde0uHNhgf1",
    "outputId": "ad7fa22e-26cd-48ed-b55d-46d92d128de2"
   },
   "outputs": [],
   "source": [
    "for key in ['DESCR', 'target_names', 'feature_names']:\n",
    "    print(key, iris[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xp-ss8CqDePE",
    "outputId": "83531e6a-7012-471e-a7be-a3d98787e264"
   },
   "outputs": [],
   "source": [
    "print(\"IRIS data shape:\", iris.data.shape)\n",
    "print(\"IRIS target shape:\", iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.data)\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbDU5t_xDPOA"
   },
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QETu-3yMDPOA"
   },
   "outputs": [],
   "source": [
    "# Import the functions for logistic regression from sklearn module\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiDoyiRaDPOM"
   },
   "source": [
    "### 2.1 Binary classification(logistic regression) (using 2 features)\n",
    "\n",
    "For binary classification, we will classify the iris dataset into two classes: Virginica and non-Virginica. We will use the last two features of the dataset (petal length and petal width) for this classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSaFTFRiDPOM"
   },
   "outputs": [],
   "source": [
    "# First we will create a binary target (0 or 1) for Virginica and non-Virginica\n",
    "# Target names: ['setosa' 'versicolor' 'virginica']\n",
    "# Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "y = ___ # Fill in the blank\n",
    "\n",
    "# Use petal length and petal width as features\n",
    "X = ___ # Fill in the blank\n",
    "\n",
    "# Create a logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "log_reg.___ # Fill in the blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.intercept_, log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "y_PiptnYDPOT",
    "outputId": "88ec1538-cb39-46a4-c9e6-3977f5cdcaf3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2-dimensional coordinate.\n",
    "xx, yy = np.meshgrid(np.arange(0, 8, 0.01), np.arange(0, 3.0, 0.01))\n",
    "Z = log_reg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "# Define size of figure\n",
    "plt.figure(1, figsize = (8, 6))\n",
    "# To see decision boundary, predicted value for each points are colored\n",
    "plt.pcolormesh(xx, yy, Z, cmap = \"RdBu\"\n",
    "               ,vmin = -.2 , vmax = 1.2)\n",
    "# Plot Datapoints with corresponding color\n",
    "plt.scatter(X[:,0], X[:, 1], c=y, s=50,\n",
    "           cmap=\"RdBu\", vmin= -.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "# Labeling axis\n",
    "plt.xlabel(\"Petal length\")\n",
    "plt.ylabel(\"Petal width\")\n",
    "# Add decision boundary with coef and intercept\n",
    "xx = np.linspace(4, 6.)\n",
    "yy = -(log_reg.intercept_[0] + log_reg.coef_[0][0] * xx) / log_reg.coef_[0][1]\n",
    "plt.plot(xx, yy, \"k--\", label = \"Decision Boundary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Jn8SPeCDPOV",
    "outputId": "304c5c3c-009a-49ac-b5a3-1100cd5daa89"
   },
   "outputs": [],
   "source": [
    "# Calculate the accuracy of the model\n",
    "predictions = ___ # Fill in the blank\n",
    "accuracy = ___ # Fill in the blank\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qz0kBk78EB5I"
   },
   "source": [
    "### 2.2 Binary classification(logistic regression) (using 4 features)\n",
    "\n",
    "**Setosa vs non-setosa** classification using all four features of the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipm2dfsqCU6W"
   },
   "outputs": [],
   "source": [
    "# Target names: ['setosa' 'versicolor' 'virginica']\n",
    "# Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "# Use 4 features: sepal width, sepal length, petal width and petal length \n",
    "\"\"\"\n",
    "TODO: \n",
    "1. Create a binary target (0 or 1) for Setosa and non-Setosa\n",
    "2. Use 4 features: sepal width, sepal length, petal width and petal length\n",
    "3. Define classifier name \"lr\"\n",
    "4. Fit the model to the data\n",
    "5. Calculate the accuracy of the model\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy:\" , accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aETVUM1DPOX"
   },
   "source": [
    "### 2.3 Multi-class classification(logistic regression) (using 2 features)\n",
    "\n",
    "For multi-class classification, we will classify the iris dataset into three classes: Setosa, Versicolor, and Virginica. We will use the last two features of the dataset (petal length and petal width) for this classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzqBMljvDPOX"
   },
   "outputs": [],
   "source": [
    "# Classify all three species of iris\n",
    "# Target names: ['setosa' 'versicolor' 'virginica']\n",
    "# Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "y = ___ # Fill in the blank\n",
    "# Use petal length and petal width as features\n",
    "X = ___ # Fill in the blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression model\n",
    "multi_log_reg = LogisticRegression(___) # Fill in the blank\n",
    "\n",
    "# Fit the model to the data\n",
    "multi_log_reg.___ # Fill in the blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$softmax(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob = multi_log_reg.predict_proba(X)\n",
    "print(\"Predicted probabilities:\\n\", predict_prob[:5])\n",
    "sum_predict_prob = np.sum(predict_prob, axis=1)\n",
    "print(\"Sum of predicted probabilities:\\n\", sum_predict_prob[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3Vw_35RDPOb"
   },
   "outputs": [],
   "source": [
    "# 2-dimensional coordinate.\n",
    "xx, yy = np.meshgrid(np.arange(0, 8, 0.01), np.arange(0, 3.0, 0.01))\n",
    "Z = multi_log_reg.predict(np.c_[xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "MBYAbfTRDPOd",
    "outputId": "f68ef282-c29b-494e-84d7-cc5509d9891d"
   },
   "outputs": [],
   "source": [
    "Z = Z.reshape(xx.shape)\n",
    "# Define size of figure\n",
    "plt.figure(1, figsize=(8, 6))\n",
    "# To see decision boundary, predicted value for each points are colored\n",
    "plt.pcolormesh(xx, yy, Z,  cmap=\"RdBu\"\n",
    "               ,vmin=-.2, vmax=1.2)\n",
    "# Plot Datapoints with corresponding color\n",
    "plt.scatter(X[:,0],X[:,1],c=y,cmap=\"RdBu\"\n",
    "            ,vmin=-.2, vmax=1.2\n",
    "            ,edgecolor=\"white\", linewidth=1)\n",
    "# Labeling axis\n",
    "plt.xlabel(\"Petal length\")\n",
    "plt.ylabel(\"Petal width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XnEoaAGDDPOf",
    "outputId": "f8a9a458-c2ca-40d8-e20c-0ec5a0c66a35"
   },
   "outputs": [],
   "source": [
    "# Get accuracy of each class\n",
    "\n",
    "predictions = multi_log_reg.predict(X)\n",
    "for i in range(3):\n",
    "    # 1-vs-rest accuracy\n",
    "    class_pred = (predictions == i) * 1\n",
    "    class_y = (y == i) * 1\n",
    "    accuracy = np.sum(class_pred == class_y) / len(y)\n",
    "    print(f\"Accuracy for class {iris.target_names[i]}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "confusion = confusion_matrix(y, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=iris.target_names,\n",
    "            yticklabels=iris.target_names)\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU4FEZgMFsHd"
   },
   "source": [
    "### 2.4 Multi-class classification(logistic regression) (using 4 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target names: ['setosa' 'versicolor' 'virginica']\n",
    "# Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "# Use 4 features: sepal width, sepal length, petal width and petal length \n",
    "\"\"\"\n",
    "TODO: \n",
    "1. Use 3 targets: setosa, versicolor and virginica\n",
    "2. Use 4 features: sepal width, sepal length, petal width and petal length\n",
    "3. Define classifier name \"multi_lr\"\n",
    "4. Fit the model to the data\n",
    "5. Calculate the accuracy of the each class\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predictions = multi_lr.predict(X)\n",
    "for i in range(3):\n",
    "    # 1-vs-rest accuracy\n",
    "    class_pred = (predictions == i) * 1\n",
    "    class_y = (y == i) * 1\n",
    "    accuracy = np.sum(class_pred == class_y) / len(y)\n",
    "    print(f\"Accuracy for class {iris.target_names[i]}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Multi-class classification(MLP classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify all three species of iris with MLP classifier\n",
    "y = iris[\"target\"]\n",
    "X = iris[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H625nbElmI05",
    "outputId": "8579f027-0b0e-4627-fc2a-8e5c7c4f3f03"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier_MLP = MLPClassifier(activation = 'relu', solver= 'lbfgs')\n",
    "classifier_MLP.fit(X, y)\n",
    "classifier_MLP.score(X, y)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab4_Classification_for students.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "c1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
