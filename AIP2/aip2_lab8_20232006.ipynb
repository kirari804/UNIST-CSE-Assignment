{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfMsZu5ae-ML"
      },
      "source": [
        "# Exercise 1: TensorFlow Implementation (Filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QirfmvJDe0oe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_sample_image\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)\n",
        "\n",
        "# Check your device for learning\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUa0ZFkNfUgC"
      },
      "outputs": [],
      "source": [
        "# Get sample images and normalize\n",
        "china = load_sample_image(\"china.jpg\") / 255\n",
        "flower = load_sample_image(\"flower.jpg\") / 255\n",
        "images = np.array([china, flower])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERTXF1zSfZhR"
      },
      "outputs": [],
      "source": [
        "# Print image info\n",
        "batch_size, height, width, channels = images.shape\n",
        "print(\"batch_size :\", batch_size, \"\\nheight * width :\", height, \"*\", width, \"\\nchannels :\", channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEw6_kuIf4AB"
      },
      "outputs": [],
      "source": [
        "# Visualizing\n",
        "CHINA = 0\n",
        "FLOWER = 1\n",
        "\n",
        "plt.imshow(images[CHINA][:, :, 0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(images[FLOWER][:, :, 0], cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aq3UkuqTf7SW"
      },
      "outputs": [],
      "source": [
        "# Create 2 filters\n",
        "filters = np.zeros(shape=(7, 7, channels, 2), dtype=np.float32)\n",
        "filters[:, 3, :, 0] = 1 # vertical line\n",
        "filters[3, :, :, 1] = 1 # horizontal line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLqwUga9gFtx"
      },
      "outputs": [],
      "source": [
        "# Visualizing\n",
        "plt.imshow(filters[:, :, 0, 0],cmap=\"gray\") # First filter\n",
        "plt.show()\n",
        "plt.imshow(filters[:, :, 0, 1],cmap=\"gray\") # Second filter\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP17M_IEgIWp"
      },
      "outputs": [],
      "source": [
        "# Convolutional computation using filters\n",
        "outputs = tf.nn.conv2d(images, filters, strides=1, padding=\"SAME\")\n",
        "\n",
        "plt.imshow(outputs[CHINA, :, :, 0], cmap=\"gray\") # plot 1st image's 1st feature map\n",
        "plt.show()\n",
        "plt.imshow(outputs[CHINA, :, :, 1], cmap=\"gray\") # plot 1st image's 2nd feature map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85ZRsruLgSk1"
      },
      "outputs": [],
      "source": [
        "# Temp function for cropping\n",
        "def crop(images):\n",
        "    return images[150:220, 130:250]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ustNGMYEgZMa"
      },
      "outputs": [],
      "source": [
        "# Visualizing\n",
        "print(\"Input\")\n",
        "plt.imshow(crop(images[CHINA, :, :, 0]),cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4n1noo9ga09"
      },
      "outputs": [],
      "source": [
        "# Visualizing\n",
        "for feature_map_index, filename in enumerate([\"china_vertical\", \"china_horizontal\"]):\n",
        "    print(filename)\n",
        "    plt.imshow(crop(outputs[CHINA, :, :, feature_map_index]),cmap=\"gray\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJgiGoM4gjsL"
      },
      "source": [
        "# Exercise 2: TensorFlow Implementation (Pooling Layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOe1Ose-ggnu"
      },
      "outputs": [],
      "source": [
        "# Pooling layer\n",
        "max_pool = keras.layers.MaxPool2D(pool_size=2,dtype=\"float64\")\n",
        "outputs = max_pool(images)\n",
        "\n",
        "# Visualizing\n",
        "plt.imshow(images[CHINA, :, :, 0], cmap=\"gray\")\n",
        "plt.show()\n",
        "print(\"Input's H*W :\", images[CHINA, :, :, 0].shape)\n",
        "\n",
        "plt.imshow(outputs[CHINA, :, :, 0], cmap=\"gray\")\n",
        "plt.show()\n",
        "print(\"Output's H*W :\", outputs[CHINA, :, :, 0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXVCauRXgwqN"
      },
      "outputs": [],
      "source": [
        "# Get cropped images and max pooling\n",
        "cropped_images = np.array([crop(image) for image in images], dtype=np.float32)\n",
        "output = max_pool(cropped_images)\n",
        "\n",
        "# Show the figures side-by-side in a grid\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "gs = mpl.gridspec.GridSpec(nrows=2, ncols=2, width_ratios=[2, 2])\n",
        "\n",
        "# Plot the 1st image\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax1.set_title(\"Input\", fontsize=14)\n",
        "ax1.imshow(cropped_images[CHINA])\n",
        "ax1.axis(\"off\")\n",
        "\n",
        "# Plot the output for the 1st image\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.set_title(\"Output\", fontsize=14)\n",
        "ax2.imshow(output[CHINA])\n",
        "ax2.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmYQY700hHfe"
      },
      "outputs": [],
      "source": [
        "# Depth-wise max pooling layer\n",
        "def depth_pool(images):\n",
        "    with tf.device('/CPU:0'):\n",
        "        dp = keras.layers.Lambda(lambda X: tf.nn.max_pool(X, ksize=(1, 1, 1, 3), strides=(1, 1, 1, 3), padding=\"VALID\"), dtype=\"float64\")\n",
        "        return dp(images)\n",
        "\n",
        "output = depth_pool(images)\n",
        "print(\"images :\", images.shape) # N * H * W * C\n",
        "print(\"output :\", output.shape) # N * H * W * C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmblWnbLhVQn"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot the 1st image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Input\", fontsize=14)\n",
        "plt.imshow(cropped_images[CHINA])\n",
        "\n",
        "# Plot the output for the 1st image\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Output\", fontsize=14)\n",
        "plt.imshow(depth_pool(cropped_images)[CHINA, ..., 0],cmap=\"gray\")\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swsshrvfhbXA"
      },
      "outputs": [],
      "source": [
        "# Average Pooling\n",
        "avg_pool = keras.layers.AvgPool2D(pool_size=2)\n",
        "output_avg = avg_pool(cropped_images)\n",
        "\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "gs = mpl.gridspec.GridSpec(nrows=2, ncols=2, width_ratios=[2, 2])\n",
        "\n",
        "# Plot the 1st image\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax1.set_title(\"Input\", fontsize=14)\n",
        "ax1.imshow(cropped_images[CHINA])\n",
        "ax1.axis(\"off\")\n",
        "\n",
        "# Plot the output for the 1st image\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.set_title(\"Output\", fontsize=14)\n",
        "ax2.imshow(output_avg[CHINA])\n",
        "ax2.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC5T8R3whhM1"
      },
      "outputs": [],
      "source": [
        "# Global average pooling\n",
        "global_avg_pool = keras.layers.GlobalAvgPool2D(dtype=\"float64\")\n",
        "output = global_avg_pool(images)\n",
        "\n",
        "print(\"images :\", images.shape)   # N * H * W * C\n",
        "print(\"output :\", output.shape)   # N * C\n",
        "print(\"china  :\", output[CHINA])  # R, G, B\n",
        "print(\"flower :\", output[FLOWER]) # R, G, B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4ap-aighuE-"
      },
      "source": [
        "# Exercise 3: CNN Architectures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYrmDh_4h-Wg"
      },
      "outputs": [],
      "source": [
        "# Simple CNN model\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
        "        input_shape=[28, 28, 1] # Shape from fashion mnist image\n",
        "    ),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIoaAqK0iEXz"
      },
      "outputs": [],
      "source": [
        "# Load fashion mnist dataset\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:] # train data point: 5000, valid: others\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:] # train data point: 5000, valid: others\n",
        "\n",
        "# Normalization\n",
        "X_mean = X_train.mean(axis=0, keepdims=True)\n",
        "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
        "X_train = (X_train - X_mean) / X_std\n",
        "X_valid = (X_valid - X_mean) / X_std\n",
        "X_test = (X_test - X_mean) / X_std\n",
        "\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_valid = X_valid[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuDV73c4iKZ8"
      },
      "outputs": [],
      "source": [
        "# Compile the CNN model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",metrics=[\"accuracy\"])\n",
        "\n",
        "# Training\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid,y_valid))\n",
        "\n",
        "# Evaluation\n",
        "score = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-g3ZI9yvXMd"
      },
      "outputs": [],
      "source": [
        "# Prediction\n",
        "X_new = X_test[:10]\n",
        "y_pred = model.predict(X_new)\n",
        "\n",
        "# Compared to test and predicted results\n",
        "print(\"Ground truth data:\", y_test[:10])\n",
        "print(\"Prediction result:\", y_pred.argmax(axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTRmVejqvQCm"
      },
      "source": [
        "# Exercise 4: ResNet with subclassing & sequential API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2ioyXyYlsiw"
      },
      "outputs": [],
      "source": [
        "# Define a residual unit for ResNet-34\n",
        "class ResidualUnit(keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = keras.activations.get(activation) # relu activation inthis example\n",
        "        self.main_layers = [\n",
        "            keras.layers.Conv2D(filters, 3, strides=strides, padding=\"same\", use_bias=False),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            self.activation,\n",
        "            keras.layers.Conv2D(filters, 3, strides=1, padding=\"same\", use_bias=False),\n",
        "            keras.layers.BatchNormalization()\n",
        "        ]\n",
        "        # To make short cut\n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [\n",
        "                keras.layers.Conv2D(filters, 1, strides=strides, padding=\"same\", use_bias=False),\n",
        "                keras.layers.BatchNormalization()\n",
        "            ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "\n",
        "        # Forward pass through main layers\n",
        "        for layer in self.main_layers:\n",
        "            Z = layer(Z)\n",
        "\n",
        "        # Forward pass through skip layers\n",
        "        skip_Z = inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_Z = layer(skip_Z)\n",
        "\n",
        "        # Combine main path and skip path\n",
        "        return self.activation(Z + skip_Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67ckpRyclsix"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(64, 7, strides=2, input_shape=[28, 28, 1], padding=\"same\", use_bias=False))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\n",
        "\n",
        "\n",
        "# [64, 64, 64, 128, 128, 128, 128, 256, 256, 256, 256, 256, 256, 512, 512, 512] for ResNet-34\n",
        "prev_filters = 64\n",
        "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    model.add(ResidualUnit(filters, strides=strides)) # Adding Residual model\n",
        "    prev_filters = filters\n",
        "\n",
        "model.add(keras.layers.GlobalAvgPool2D())\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAV208n5vvjw"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udrP6Pb7wtGt"
      },
      "source": [
        "# Exercise 5: Training ResNet-34 for CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GE2LVPgwwHg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def visualize_data(images, categories, class_names):\n",
        "    fig = plt.figure(figsize=(14, 6))\n",
        "    fig.patch.set_facecolor('white')\n",
        "    for i in range(3 * 7):\n",
        "        plt.subplot(3, 7, i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.imshow(images[i])\n",
        "        class_index = categories[i].argmax()\n",
        "        plt.xlabel(class_names[class_index])\n",
        "    plt.show()\n",
        "\n",
        "# Define CIFAR-10 class names\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalization and one-hot encoding\n",
        "x_train = x_train / 255.0\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "x_test = x_test / 255.0\n",
        "y_test = to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzfC_mW3w1wl"
      },
      "outputs": [],
      "source": [
        "# Visualizing\n",
        "print(x_train.shape, y_train.shape)\n",
        "visualize_data(x_train, y_train, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkeUBBzTlsiz"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(64, 7, strides=2, input_shape=[32, 32, 3], padding=\"same\", use_bias=False))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\n",
        "\n",
        "# [64, 64, 64, 128, 128, 128, 128, 256, 256, 256, 256, 256, 256, 512, 512, 512]\n",
        "prev_filters = 64\n",
        "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    model.add(ResidualUnit(filters, strides=strides))\n",
        "    prev_filters = filters\n",
        "\n",
        "model.add(keras.layers.GlobalAvgPool2D())\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJtgcfePxHPd"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kZAwLs8xFU3"
      },
      "outputs": [],
      "source": [
        "# Compile and train the model\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rDQg_0EwvJ1"
      },
      "source": [
        "# Exercise 6: CIFAR10 with data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auCfEW-RxPsh"
      },
      "outputs": [],
      "source": [
        "# For data augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalization and one-hot encoding\n",
        "x_train = x_train / 255.0\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "x_test = x_test / 255.0\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# Visualizing\n",
        "visualize_data(x_train, y_train, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmIfUKp9xRZN"
      },
      "outputs": [],
      "source": [
        "# Shift range and flip\n",
        "width_shift  = 3 / 32\n",
        "height_shift = 3 / 32\n",
        "flip = True\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=flip,\n",
        "    width_shift_range=width_shift,\n",
        "    height_shift_range=height_shift,\n",
        ")\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Define iterator\n",
        "it = datagen.flow(x_train, y_train, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g3JfZFqlsi3"
      },
      "outputs": [],
      "source": [
        "# Visualizing augmented data\n",
        "batch_images, batch_labels = next(it)\n",
        "visualize_data(batch_images, batch_labels, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBA4GAr3xSZG"
      },
      "outputs": [],
      "source": [
        "# Re-train the model with data augmentation\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\",metrics=[\"accuracy\"])\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPOYjrhoxXzf"
      },
      "source": [
        "# Assignment 1: Define ResNet-50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md2L_ASilsj9"
      },
      "outputs": [],
      "source": [
        "class ResidualUnit50(keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Relu activation in this example\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.main_layers = [\n",
        "            keras.layers.Conv2D(filters, 1 ,strides=strides, padding=\"same\", use_bias=False),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            self.activation,\n",
        "            keras.layers.Conv2D(filters,3 ,strides=1, padding=\"same\", use_bias=False),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            self.activation,\n",
        "            keras.layers.Conv2D(4*filters,1 ,strides=1, padding=\"same\", use_bias=False),\n",
        "            keras.layers.BatchNormalization(),\n",
        "        ]\n",
        "\n",
        "        self.skip_layers = [] # To make skip connection\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [\n",
        "                keras.layers.Conv2D(4*filters, 2, strides=strides, padding = \"same\", use_bias=False),\n",
        "                keras.layers.BatchNormalization()\n",
        "            ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.main_layers: Z = layer(Z)\n",
        "        skip_Z = inputs\n",
        "        for layer in self.skip_layers: skip_Z = layer(skip_Z)\n",
        "        return self.activation(Z + skip_Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWh8cPoklsj-"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(64, 7, strides=2, input_shape=[32, 32, 3], padding=\"same\", use_bias=False))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\n",
        "\n",
        "prev_filters = 0\n",
        "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    model.add(ResidualUnit50(filters, strides=strides))\n",
        "    prev_filters = filters\n",
        "\n",
        "model.add(keras.layers.GlobalAvgPool2D())\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0fwk_VgxaAL"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\",metrics=[\"accuracy\"])\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))\n",
        "score = model.evaluate(x_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}